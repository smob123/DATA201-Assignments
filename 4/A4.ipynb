{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA201 - Assignment 4\n",
    "\n",
    "Please use this page http://apps.ecs.vuw.ac.nz/submit/DATA201 for submitssion and submit only this single Jupyter notebook with your code added into it at the appropriate places.\n",
    "\n",
    "The due date is **Saturday 30th May, before midnight**.\n",
    "\n",
    "The dataset for this assignment is file **whitewine.csv** which is provided with this notebook.\n",
    "\n",
    "Please choose menu items *Kernel => Restart & Run All* then *File => Save and Checkpoint* in Jupyter before submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was adapted from the Wine Quality Dataset (https://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "For more information, read [Cortez et al., 2009: http://dx.doi.org/10.1016/j.dss.2009.05.016].\n",
    "\n",
    "Input variables (based on physicochemical tests):\n",
    "\n",
    "    1 - fixed acidity \n",
    "    2 - volatile acidity \n",
    "    3 - citric acid \n",
    "    4 - residual sugar \n",
    "    5 - chlorides \n",
    "    6 - free sulfur dioxide \n",
    "    7 - total sulfur dioxide \n",
    "    8 - density \n",
    "    9 - pH \n",
    "    10 - sulphates \n",
    "    11 - alcohol \n",
    "Output variable (based on sensory data):\n",
    "\n",
    "    12 - quality (0: normal wine, 1: good wine)\n",
    "    \n",
    "## Problem statement\n",
    "Predict the quality of a wine given its input variables. Use AUC (area under the receiver operating characteristic curve) as the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load and explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        0  \n",
       "1      9.5        0  \n",
       "2     10.1        0  \n",
       "3      9.9        0  \n",
       "4      9.9        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"whitewine.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4715 entries, 0 to 4714\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed_acidity         4715 non-null   float64\n",
      " 1   volatile_acidity      4715 non-null   float64\n",
      " 2   citric_acid           4715 non-null   float64\n",
      " 3   residual_sugar        4715 non-null   float64\n",
      " 4   chlorides             4715 non-null   float64\n",
      " 5   free_sulfur_dioxide   4715 non-null   float64\n",
      " 6   total_sulfur_dioxide  4715 non-null   float64\n",
      " 7   density               4715 non-null   float64\n",
      " 8   pH                    4715 non-null   float64\n",
      " 9   sulphates             4715 non-null   float64\n",
      " 10  alcohol               4715 non-null   float64\n",
      " 11  quality               4715 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 442.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3655\n",
       "1    1060\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this dataset is unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1]. Split the given data using stratify sampling into 2 subsets: training (80%) and test (20%) sets. Use random_state = 42. [1 points]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop(['quality'], axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=42, stratify=data['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2]. Use ``GridSearchCV`` and ``Pipeline`` to tune hyper-parameters for 3 different classifiers including ``KNeighborsClassifier``, ``LogisticRegression`` and ``svm.SVC`` and report the corresponding AUC values on the training and test sets. Note that a scaler may need to be inserted into each pipeline. [6 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You may want to use `kernel='rbf'` and tune `C` and `gamma` for `svm.SVC`. Find out how to enable probability estimates (for Question 3).\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, x_train.columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7889713679745494\n",
      "best params\n",
      "{'classifier__C': 100}\n",
      "score\n",
      "0.7889713679745494\n",
      "AUC:\n",
      "train\n",
      "0.7868054390470537\n",
      "test\n",
      "0.7986539503910385\n"
     ]
    }
   ],
   "source": [
    "clf1 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "clf1.fit(x_train, y_train)\n",
    "print(clf1.score(x_test, y_test))\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10, 100],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf1, param_grid, cv=10)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('best params')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print('score')\n",
    "print(grid_search.score(x_test, y_test))\n",
    "\n",
    "print('AUC:')\n",
    "print('train')\n",
    "print(roc_auc_score(y_train, grid_search.predict_proba(x_train)[:,1]))\n",
    "\n",
    "print('test')\n",
    "print(roc_auc_score(y_test, grid_search.predict_proba(x_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8165429480381761\n",
      "best params\n",
      "{'classifier__n_neighbors': 3}\n",
      "score\n",
      "0.8250265111346765\n",
      "AUC:\n",
      "train\n",
      "0.965423995947655\n",
      "test\n",
      "0.8494695816018379\n"
     ]
    }
   ],
   "source": [
    "clf2 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', KNeighborsClassifier())])\n",
    "clf2.fit(x_train, y_train)\n",
    "print(clf2.score(x_test, y_test))\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 10],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf2, param_grid, cv=10)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('best params')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print('score')\n",
    "print(grid_search.score(x_test, y_test))\n",
    "\n",
    "print('AUC:')\n",
    "print('train')\n",
    "print(roc_auc_score(y_train, grid_search.predict_proba(x_train)[:,1]))\n",
    "\n",
    "print('test')\n",
    "print(roc_auc_score(y_test, grid_search.predict_proba(x_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8197242841993637\n",
      "best params\n",
      "{'classifier__C': 10, 'classifier__gamma': 'scale'}\n",
      "score\n",
      "0.8335100742311771\n",
      "AUC:\n",
      "train\n",
      "0.9378488533412488\n",
      "test\n",
      "0.8485468342668353\n"
     ]
    }
   ],
   "source": [
    "clf3 = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', SVC(kernel='rbf', probability=True))])\n",
    "clf3.fit(x_train, y_train)\n",
    "print(clf3.score(x_test, y_test))\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__C': [0.1, 1.0, 10],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf3, param_grid, cv=10)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('best params')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print('score')\n",
    "print(grid_search.score(x_test, y_test))\n",
    "\n",
    "print('AUC:')\n",
    "print('train')\n",
    "print(roc_auc_score(y_train, grid_search.predict_proba(x_train)[:,1]))\n",
    "\n",
    "print('test')\n",
    "print(roc_auc_score(y_test, grid_search.predict_proba(x_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3]. Train a soft ``VotingClassifier`` with the estimators are the three tuned pipelines obtained from [2]. Report the AUC values on the training and test sets. Comment on the performance of the ensemble model. [1 point]**\n",
    "\n",
    "Hint: consider the voting method.\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "0.8260869565217391\n",
      "AUC:\n",
      "train\n",
      "0.9282265506026894\n",
      "test\n",
      "0.880068657563947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vclf = VotingClassifier(estimators=[('lr', clf1), ('knn', clf2), ('svc', clf3)], voting='soft')\n",
    "vclf = vclf.fit(x_train,y_train)\n",
    "\n",
    "print('score')\n",
    "print(vclf.score(x_test, y_test))\n",
    "\n",
    "print('AUC:')\n",
    "print('train')\n",
    "print(roc_auc_score(y_train, vclf.predict_proba(x_train)[:,1]))\n",
    "\n",
    "print('test')\n",
    "print(roc_auc_score(y_test, vclf.predict_proba(x_test)[:,1]))\n",
    "\n",
    "# the values seem to be close to the avergae of the scores of the previous classifications except for the test AUC values, which\n",
    "# is higher than all the pervious values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4]. Redo [3] with a sensible set of ``weights`` for the estimators. Comment on the performance of the ensemble model in this case. [1 point]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score\n",
      "0.8335100742311771\n",
      "AUC:\n",
      "train\n",
      "0.9387623248070619\n",
      "test\n",
      "0.8770423044162817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vclf = VotingClassifier(estimators=[('lr', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[1, 2, 1])\n",
    "vclf = vclf.fit(x_train,y_train)\n",
    "\n",
    "print('score')\n",
    "print(vclf.score(x_test, y_test))\n",
    "\n",
    "print('AUC:')\n",
    "print('train')\n",
    "print(roc_auc_score(y_train, vclf.predict_proba(x_train)[:,1]))\n",
    "\n",
    "print('test')\n",
    "print(roc_auc_score(y_test, vclf.predict_proba(x_test)[:,1]))\n",
    "\n",
    "# it looks like that the accuracy, and the AUC scores have increased slightly from the previous question except for the AUC \n",
    "# value for the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5]. Use the ``VotingClassifier`` with ``GridSearchCV`` to tune the hyper-parameters of the individual estimators. The parameter grid should be a combination of those in [2]. Report the AUC values on the training and test sets. Comment on the performance of the ensemble model. [1 point]**\n",
    "\n",
    "Note that it may take a long time to run your code for this question.\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/ensemble.html#using-the-votingclassifier-with-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'knn__classifier__n_neighbors': 3, 'lr__classifier__C': 100.0, 'svc__classifier__C': 10, 'svc__classifier__gamma': 'auto'}\n",
      "score\n",
      "0.8419936373276776\n",
      "AUC:\n",
      "train\n",
      "0.9721836847946725\n",
      "test\n",
      "0.892393464625868\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'lr__classifier__C': [1.0, 100.0],\n",
    "    'knn__classifier__n_neighbors': [3, 5, 7, 10],\n",
    "    'svc__classifier__C': [0.1, 1.0, 10],\n",
    "    'svc__classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=vclf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print('best params')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print('score')\n",
    "print(grid_search.score(x_test, y_test))\n",
    "\n",
    "print('AUC:')\n",
    "print('train')\n",
    "print(roc_auc_score(y_train, grid_search.predict_proba(x_train)[:,1]))\n",
    "\n",
    "print('test')\n",
    "print(roc_auc_score(y_test, grid_search.predict_proba(x_test)[:,1]))\n",
    "\n",
    "# it seems that the given parameters have increased the predictions score, and AUC values to give better results than the\n",
    "# values of the previous two classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
