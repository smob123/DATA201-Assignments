{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3 - Data Transformation using ColumnTransformer and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Please contact Binh Nguyen (binh.p.nguyen@vuw.ac.nz) if you have any questions regarding this tutorial.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Ames Iowa Housing Dataset which can be found on Kaggle (https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). More details about the dataset can be found here: http://jse.amstat.org/v19n3/decock.pdf\n",
    "\n",
    "The dataset contains residential property sales data from Ames, Iowa from 2006 to 2010. There are 79 features/attributes (columns) of data on 1,460 properties, and each property associates with its final sale price.\n",
    "\n",
    "With this dataset, the machine learning problem could be *predicting the sale price* for each property using its features.\n",
    "\n",
    "Instead of using the full dataset with all 79 features, we focus on a subset of only 10 of them. Using this smaller subset allows us to concentrate on machine learning techniques without being overloaded with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CollgCr</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>2003</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1710</td>\n",
       "      <td>548</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>Ex</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veenker</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>1976</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Ex</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CollgCr</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>2001</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1786</td>\n",
       "      <td>608</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>Ex</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>1915</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1717</td>\n",
       "      <td>642</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Gd</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoRidge</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>2000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2198</td>\n",
       "      <td>836</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Ex</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Neighborhood Exterior1st  YearBuilt  LotFrontage  GrLivArea  GarageArea  \\\n",
       "0      CollgCr     VinylSd       2003         65.0       1710         548   \n",
       "1      Veenker     MetalSd       1976         80.0       1262         460   \n",
       "2      CollgCr     VinylSd       2001         68.0       1786         608   \n",
       "3      Crawfor     Wd Sdng       1915         60.0       1717         642   \n",
       "4      NoRidge     VinylSd       2000         84.0       2198         836   \n",
       "\n",
       "   BedroomAbvGr  FullBath  OverallQual HeatingQC  SalePrice  \n",
       "0             3         2            7        Ex     208500  \n",
       "1             3         2            6        Ex     181500  \n",
       "2             3         2            7        Ex     223500  \n",
       "3             3         1            7        Gd     140000  \n",
       "4             4         2            8        Ex     250000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed = 42\n",
    "\n",
    "housing = pd.read_csv('ames_housing_sample.csv')\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a text file storing descriptions of each of the columns in the dataset. Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighborhood: Physical locations within Ames city limits\n",
      "\n",
      "       Blmngtn\tBloomington Heights\n",
      "       Blueste\tBluestem\n",
      "       BrDale\tBriardale\n",
      "       BrkSide\tBrookside\n",
      "       ClearCr\tClear Creek\n",
      "       CollgCr\tCollege Creek\n",
      "       Crawfor\tCrawford\n",
      "       Edwards\tEdwards\n",
      "       Gilbert\tGilbert\n",
      "       IDOTRR\tIowa DOT and Rail Road\n",
      "       MeadowV\tMeadow Village\n",
      "       Mitchel\tMitchell\n",
      "       Names\tNorth Ames\n",
      "       NoRidge\tNorthridge\n",
      "       NPkVill\tNorthpark Villa\n",
      "       NridgHt\tNorthridge Heights\n",
      "       NWAmes\tNorthwest Ames\n",
      "       OldTown\tOld Town\n",
      "       SWISU\tSouth & West of Iowa State University\n",
      "       Sawyer\tSawyer\n",
      "       SawyerW\tSawyer West\n",
      "       Somerst\tSomerset\n",
      "       StoneBr\tStone Brook\n",
      "       Timber\tTimberland\n",
      "       Veenker\tVeenker\n",
      "\n",
      "Exterior1st: Exterior covering on house\n",
      "\n",
      "       AsbShng\tAsbestos Shingles\n",
      "       AsphShn\tAsphalt Shingles\n",
      "       BrkComm\tBrick Common\n",
      "       BrkFace\tBrick Face\n",
      "       CBlock\tCinder Block\n",
      "       CemntBd\tCement Board\n",
      "       HdBoard\tHard Board\n",
      "       ImStucc\tImitation Stucco\n",
      "       MetalSd\tMetal Siding\n",
      "       Other\tOther\n",
      "       Plywood\tPlywood\n",
      "       PreCast\tPreCast\t\n",
      "       Stone\tStone\n",
      "       Stucco\tStucco\n",
      "       VinylSd\tVinyl Siding\n",
      "       Wd Sdng\tWood Siding\n",
      "       WdShing\tWood Shingles\n",
      "        \n",
      "YearBuilt: Original construction date\n",
      "\n",
      "LotFrontage: Linear feet of street connected to property\n",
      "\n",
      "GrLivArea: Above grade (ground) living area square feet\n",
      "\n",
      "GarageArea: Size of garage in square feet\n",
      "\n",
      "BedroomAbvGr: Bedrooms above grade (does NOT include basement bedrooms)\n",
      "\n",
      "FullBath: Full bathrooms above grade\n",
      "\n",
      "OverallQual: Rates the overall material and finish of the house\n",
      "\n",
      "       10\tVery Excellent\n",
      "       9\tExcellent\n",
      "       8\tVery Good\n",
      "       7\tGood\n",
      "       6\tAbove Average\n",
      "       5\tAverage\n",
      "       4\tBelow Average\n",
      "       3\tFair\n",
      "       2\tPoor\n",
      "       1\tVery Poor\n",
      "       \n",
      "HeatingQC: Heating quality and condition\n",
      "\n",
      "       Ex\tExcellent\n",
      "       Gd\tGood\n",
      "       TA\tAverage/Typical\n",
      "       Fa\tFair\n",
      "       Po\tPoor\n",
      "\n",
      "SalePrice: Final sale price in dollars\n"
     ]
    }
   ],
   "source": [
    "print(open('ames_housing_sample_info.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Neighborhood  1460 non-null   object \n",
      " 1   Exterior1st   1460 non-null   object \n",
      " 2   YearBuilt     1460 non-null   int64  \n",
      " 3   LotFrontage   1201 non-null   float64\n",
      " 4   GrLivArea     1460 non-null   int64  \n",
      " 5   GarageArea    1460 non-null   int64  \n",
      " 6   BedroomAbvGr  1460 non-null   int64  \n",
      " 7   FullBath      1460 non-null   int64  \n",
      " 8   OverallQual   1460 non-null   int64  \n",
      " 9   HeatingQC     1460 non-null   object \n",
      " 10  SalePrice     1460 non-null   int64  \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 125.6+ KB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1971.267808</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>1515.463699</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.565068</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.202904</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>525.480383</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.550916</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1872.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1954.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1129.500000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1973.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1776.750000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         YearBuilt  LotFrontage    GrLivArea   GarageArea  BedroomAbvGr  \\\n",
       "count  1460.000000  1201.000000  1460.000000  1460.000000   1460.000000   \n",
       "mean   1971.267808    70.049958  1515.463699   472.980137      2.866438   \n",
       "std      30.202904    24.284752   525.480383   213.804841      0.815778   \n",
       "min    1872.000000    21.000000   334.000000     0.000000      0.000000   \n",
       "25%    1954.000000    59.000000  1129.500000   334.500000      2.000000   \n",
       "50%    1973.000000    69.000000  1464.000000   480.000000      3.000000   \n",
       "75%    2000.000000    80.000000  1776.750000   576.000000      3.000000   \n",
       "max    2010.000000   313.000000  5642.000000  1418.000000      8.000000   \n",
       "\n",
       "          FullBath  OverallQual      SalePrice  \n",
       "count  1460.000000  1460.000000    1460.000000  \n",
       "mean      1.565068     6.099315  180921.195890  \n",
       "std       0.550916     1.382997   79442.502883  \n",
       "min       0.000000     1.000000   34900.000000  \n",
       "25%       1.000000     5.000000  129975.000000  \n",
       "50%       2.000000     6.000000  163000.000000  \n",
       "75%       2.000000     7.000000  214000.000000  \n",
       "max       3.000000    10.000000  755000.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our dataset contains a mixture of categorical and numerical columns. It also has missing data, the numerical attributes have different ranges, and there are continuous, nominal, and ordinal data; each of them needs their own transformation. In order to **apply different transformations to different columns of data**, we will need to use the `ColumnTransformer` (https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data to a training set (80%) and a test set (20%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then separate the *predictors* and the *labels* since we don't necessarily want to apply the same transformations to the predictors and the target values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(\"SalePrice\", axis=1) # drop labels for training set\n",
    "y_train = train_set[\"SalePrice\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set.drop(\"SalePrice\", axis=1)\n",
    "y_test = test_set[\"SalePrice\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we import necessary modules for data transformation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply any number of transformations to a distinct set of columns by using a **pipeline** within the `ColumnTransformer`. Since column `LotFrontage` has missing values, for continous columns, let's use `SimpleImputer` with `strategy='mean'` to handle missing values, then apply `MinMaxScaler` to normalize data to [0, 1]. So the pipeline for continous columns has 2 steps (i.e., 2 transformers): `SimpleImputer` and `MinMaxScaler`. For ordinal columns and norminal columns, we use only one transformer: `OrdinalEncoder` and `OneHotEncoder`, respectively, for each of their pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous pipeline\n",
    "con_impute = SimpleImputer(strategy='mean')\n",
    "con_normalize = MinMaxScaler()\n",
    "con_steps = [('imp', con_impute), ('norm', con_normalize)]\n",
    "con_pipe = Pipeline(con_steps)\n",
    "\n",
    "# Nominal pipeline\n",
    "nom_onehot = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "nom_steps = [('onehot', nom_onehot)]\n",
    "nom_pipe = Pipeline(nom_steps)\n",
    "\n",
    "# Ordinal pipeline\n",
    "order = [['Po', 'Fa', 'TA', 'Gd', 'Ex']]\n",
    "ord_encode = OrdinalEncoder(order)\n",
    "ord_steps = [('encode', ord_encode)]\n",
    "ord_pipe = Pipeline(ord_steps)\n",
    "\n",
    "# ColumnTransformer setup\n",
    "con_cols = ['YearBuilt', 'LotFrontage', 'GrLivArea', 'GarageArea', 'BedroomAbvGr', 'FullBath', 'OverallQual']\n",
    "nom_cols = ['Neighborhood', 'Exterior1st']\n",
    "ord_cols = ['HeatingQC']\n",
    "\n",
    "transformers = [('con', con_pipe, con_cols),\n",
    "                ('nom', nom_pipe, nom_cols),\n",
    "                ('ord', ord_pipe, ord_cols)]\n",
    "col_transform = ColumnTransformer(transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's transform the training set then look at the first sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61594203, 0.16780822, 0.18462698, 0.20733427, 0.375     ,\n",
       "        0.33333333, 0.44444444, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 2.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the column transformer then transform the training data\n",
    "X_train_transformed = col_transform.fit_transform(X_train)\n",
    "X_train_transformed[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the trained column transformer on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65942029, 0.16780822, 0.13828184, 0.18617772, 0.375     ,\n",
       "        0.33333333, 0.55555556, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 2.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data using the column transformer which has just been trained\n",
    "X_test_transformed = col_transform.transform(X_test)\n",
    "X_test_transformed[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, missing data may appear in any column in future data. So it is practical to impute missing values at the beginning of each column tranformer. Please revise the code to apply the following transformations for 3 different types of columns.\n",
    "+ Continous columns: use `SimpleImputer` with `strategy='mean'` to handle missing values, then apply `MinMaxScaler` to normalize data to [0, 1].\n",
    "+ Ordinal columns: use `SimpleImputer` with `strategy='most_frequent'` to handle missing values, and apply `OrdinalEncoder` to convert each value to a number, then use `MinMaxScaler` for data normalization.\n",
    "+ Norminal columns: use `SimpleImputer` with `strategy='most_frequent'` to handle missing values, and apply `OneHotEncoder` to convert each value to a numerical vector. Data normalization is not needed (why?).\n",
    "\n",
    "Please note that data normalization may not be helpful in this regression problem. However, in this tutorial, including data normalization in each pipeline is good for your practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1. Revised code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2. Modelling:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying separate transformations to separate groups of columns, we can pass this result to a machine learning model. To connect the `ColumnTransformer` to the machine learning estimator, we also use a **pipeline**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to create another pipeline containing 2 steps: the column transformer that we have just developed, and a linear regressor (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Then fit the pipeline using our training data and test it on the test set. Report the RMSE value for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3. Another model:**\n",
    "\n",
    "Replace the linear regressor by a random forest regressor (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). Redo the steps in Question 2 and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to make further changes on the column transformer and the final pipeline in order to improve the prediction results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*At this moment, although we have already used the Linear Regressor in some examples, we have not discussed it and also the Random Forest Regressor in detail. So let's consider them \"black boxes\" in a machine learning pipeline. We will discuss those algorithms in incoming lectures.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
